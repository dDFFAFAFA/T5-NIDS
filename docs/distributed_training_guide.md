# ğŸ”¥ å•å¡ vs å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒï¼šå®Œæ•´æŒ‡å—

> æœ¬æ–‡æ¡£è¯¦ç»†å¯¹æ¯”å•å¡è®­ç»ƒä¸å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒçš„æ ¸å¿ƒåŒºåˆ«ï¼Œå¹¶æ·±å…¥è®²è§£ DataLoader å’Œ Accelerate çš„åº•å±‚åŸç†ã€‚

---

## ğŸ“Š å¯¹æ¯”æ€»è§ˆ

| æ–¹é¢ | å•å¡è®­ç»ƒ | å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒ |
|------|---------|---------------|
| GPU æŒ‡å®š | `device = torch.device("cuda:0")` | `os.environ["CUDA_VISIBLE_DEVICES"] = "4,5,6,7"` |
| æ¨¡å‹æ”¾ç½® | `model.to(device)` | `accelerator.prepare(model)` |
| æ•°æ®åŠ è½½ | æ™®é€š DataLoader | Accelerate è‡ªåŠ¨åˆ†ç‰‡ |
| æ¢¯åº¦æ›´æ–° | ç›´æ¥ `loss.backward()` | è‡ªåŠ¨è·¨å¡åŒæ­¥ |
| Batch Size | å³å®é™… batch size | æ¯å¡ batch Ã— å¡æ•° = æ€» batch |
| å¯åŠ¨æ–¹å¼ | ç›´æ¥è¿è¡Œ | `notebook_launcher` æˆ– `accelerate launch` |

---

## ğŸ–¥ï¸ æ–¹å¼ä¸€ï¼šå•å¡è®­ç»ƒ

### æ ¸å¿ƒä»£ç æ¡†æ¶

```python
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

# ============ 1. æŒ‡å®šè®¾å¤‡ ============
device = torch.device("cuda:0")  # æŒ‡å®šç¬¬ 0 å¼ å¡
# æˆ–è€…: device = torch.device("cuda:2")  # æŒ‡å®šç¬¬ 2 å¼ å¡

# ============ 2. æ¨¡å‹å‡†å¤‡ ============
model = MyModel()
model.to(device)  # æ¨¡å‹ç§»åˆ° GPU

# ============ 3. æ•°æ®åŠ è½½ ============
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)

# ============ 4. ä¼˜åŒ–å™¨ ============
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# ============ 5. è®­ç»ƒå¾ªç¯ ============
for epoch in range(num_epochs):
    for batch in train_loader:
        # æ•°æ®ç§»åˆ° GPU
        inputs = batch['input_ids'].to(device)
        labels = batch['labels'].to(device)
        
        # å‰å‘ä¼ æ’­
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        print(f"Loss: {loss.item()}")

# ============ 6. ä¿å­˜æ¨¡å‹ ============
torch.save(model.state_dict(), "model.pth")
```

### å•å¡ä¼˜ç¼ºç‚¹

| ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|
| âœ… ä»£ç ç®€å•ç›´è§‚ | âŒ æ˜¾å­˜å—é™ |
| âœ… è°ƒè¯•æ–¹ä¾¿ | âŒ è®­ç»ƒé€Ÿåº¦æ…¢ |
| âœ… æ— é€šä¿¡å¼€é”€ | âŒ æ— æ³•åˆ©ç”¨å¤šå¡èµ„æº |

---

## ğŸš€ æ–¹å¼äºŒï¼šå¤šå¡åˆ†å¸ƒå¼è®­ç»ƒ (ä½¿ç”¨ Accelerate)

### æ ¸å¿ƒä»£ç æ¡†æ¶

```python
import os
# âš ï¸ å¿…é¡»åœ¨ import torch ä¹‹å‰è®¾ç½®ï¼
os.environ["CUDA_VISIBLE_DEVICES"] = "4,5,6,7"

import torch
from accelerate import Accelerator, notebook_launcher
from torch.utils.data import DataLoader

def train_distributed():
    """
    ğŸ”¥ æ¯ä¸ª GPU è¿›ç¨‹éƒ½ä¼šç‹¬ç«‹æ‰§è¡Œè¿™ä¸ªå‡½æ•°
    Accelerate ä¼šè‡ªåŠ¨ï¼š
    - åˆ†é…ä¸åŒçš„ GPU ç»™æ¯ä¸ªè¿›ç¨‹
    - åˆ†ç‰‡æ•°æ®ï¼Œæ¯ä¸ªè¿›ç¨‹å¤„ç† 1/N çš„æ•°æ®
    - åŒæ­¥æ¢¯åº¦
    """
    
    # ============ 1. åˆ›å»º Accelerator ============
    accelerator = Accelerator()
    # accelerator.device ä¼šè‡ªåŠ¨åˆ†é…å½“å‰è¿›ç¨‹çš„ GPU
    
    # ============ 2. æ¨¡å‹å‡†å¤‡ (ä¸éœ€è¦æ‰‹åŠ¨ .to(device)) ============
    model = MyModel()
    
    # ============ 3. æ•°æ®åŠ è½½ ============
    train_loader = DataLoader(dataset, batch_size=16)  # æ¯å¡ 16
    # æ€» batch = 16 Ã— 4å¡ = 64
    
    # ============ 4. ä¼˜åŒ–å™¨ ============
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)
    
    # ============ 5. ğŸ”¥ Accelerate åŒ…è£… (æ ¸å¿ƒï¼) ============
    model, optimizer, train_loader = accelerator.prepare(
        model, optimizer, train_loader
    )
    # â†‘ è¿™ä¸€æ­¥ä¼šï¼š
    #   - è‡ªåŠ¨å°†æ¨¡å‹ç§»åˆ°å½“å‰ GPU
    #   - ç”¨ DistributedDataParallel åŒ…è£…æ¨¡å‹
    #   - ç”¨ DistributedSampler åˆ†ç‰‡æ•°æ®
    
    # ============ 6. è®­ç»ƒå¾ªç¯ ============
    for epoch in range(num_epochs):
        for batch in train_loader:
            # âš ï¸ ä¸éœ€è¦æ‰‹åŠ¨ .to(device)ï¼
            inputs = batch['input_ids']
            labels = batch['labels']
            
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            
            optimizer.zero_grad()
            accelerator.backward(loss)  # ğŸ”¥ ä½¿ç”¨ accelerator.backward()
            optimizer.step()
            
            # åªåœ¨ä¸»è¿›ç¨‹æ‰“å°
            if accelerator.is_main_process:
                print(f"Loss: {loss.item()}")
    
    # ============ 7. ä¿å­˜æ¨¡å‹ (åªåœ¨ä¸»è¿›ç¨‹) ============
    if accelerator.is_main_process:
        unwrapped_model = accelerator.unwrap_model(model)
        torch.save(unwrapped_model.state_dict(), "model.pth")

# ============ 8. ğŸ”¥ å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ ============
# Notebook ä¸­ï¼š
notebook_launcher(train_distributed, num_processes=4, use_port="29501")

# å‘½ä»¤è¡Œä¸­ï¼š
# accelerate launch --num_processes=4 train.py
```

---

## ğŸ”‘ æ ¸å¿ƒåŒºåˆ«æ€»ç»“

### 1. GPU æŒ‡å®šæ–¹å¼

```python
# å•å¡
device = torch.device("cuda:2")
model.to(device)
data.to(device)

# å¤šå¡
os.environ["CUDA_VISIBLE_DEVICES"] = "4,5,6,7"  # åœ¨ import torch ä¹‹å‰
accelerator = Accelerator()
model, optimizer, dataloader = accelerator.prepare(...)  # è‡ªåŠ¨åˆ†é…
```

### 2. åå‘ä¼ æ’­

```python
# å•å¡
loss.backward()

# å¤šå¡
accelerator.backward(loss)  # è‡ªåŠ¨åŒæ­¥æ¢¯åº¦
```

### 3. æ•°æ®å¤„ç†

```python
# å•å¡
for batch in dataloader:
    inputs = batch['x'].to(device)  # æ‰‹åŠ¨ç§»åŠ¨

# å¤šå¡
# accelerator.prepare() åï¼ŒDataLoader è‡ªåŠ¨åˆ†ç‰‡
# ä¸éœ€è¦æ‰‹åŠ¨ .to(device)
for batch in dataloader:
    inputs = batch['x']  # å·²ç»åœ¨æ­£ç¡®çš„ GPU ä¸Šäº†
```

### 4. æ‰“å°ä¸ä¿å­˜

```python
# å•å¡
print(f"Loss: {loss.item()}")
torch.save(model.state_dict(), "model.pth")

# å¤šå¡ (é¿å…é‡å¤æ‰“å°/ä¿å­˜)
if accelerator.is_main_process:
    print(f"Loss: {loss.item()}")
    unwrapped = accelerator.unwrap_model(model)
    torch.save(unwrapped.state_dict(), "model.pth")
```

### 5. Batch Size è®¡ç®—

```python
# å•å¡
batch_size = 64  # å®é™…å°±æ˜¯ 64

# å¤šå¡ (4 å¼ å¡)
batch_size = 16  # æ¯å¡ 16
# æ€» batch = 16 Ã— 4 = 64
# å­¦ä¹ ç‡å¯èƒ½éœ€è¦ Ã— 4 (çº¿æ€§ç¼©æ”¾)
```

---

## ğŸ“‹ ä¸€å¼ å›¾æ€»ç»“

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å•å¡è®­ç»ƒ                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  device = torch.device("cuda:0")                                â”‚
â”‚  model.to(device)                                               â”‚
â”‚  data.to(device)                                                â”‚
â”‚  loss.backward()                                                â”‚
â”‚  torch.save(model.state_dict(), ...)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å¤šå¡åˆ†å¸ƒå¼è®­ç»ƒ                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3"  # importå‰!     â”‚
â”‚  accelerator = Accelerator()                                    â”‚
â”‚  model, opt, loader = accelerator.prepare(model, opt, loader)   â”‚
â”‚  accelerator.backward(loss)                                     â”‚
â”‚  if accelerator.is_main_process:                                â”‚
â”‚      torch.save(accelerator.unwrap_model(model).state_dict())   â”‚
â”‚                                                                 â”‚
â”‚  å¯åŠ¨: notebook_launcher(fn, num_processes=4)                   â”‚
â”‚     æˆ–: accelerate launch --num_processes=4 script.py           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš ï¸ å¸¸è§é™·é˜±

| é™·é˜± | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| `CUDA_VISIBLE_DEVICES` ä¸ç”Ÿæ•ˆ | åœ¨ `import torch` ä¹‹åè®¾ç½® | å¿…é¡»åœ¨æœ€å¼€å¤´è®¾ç½® |
| æ‰“å°è¾“å‡ºé‡å¤ N æ¬¡ | N ä¸ªè¿›ç¨‹éƒ½åœ¨æ‰“å° | ç”¨ `if accelerator.is_main_process:` |
| ä¿å­˜çš„æ¨¡å‹æ— æ³•åŠ è½½ | ä¿å­˜äº† DDP åŒ…è£…åçš„æ¨¡å‹ | ç”¨ `accelerator.unwrap_model()` |
| `notebook_launcher` æŠ¥é”™ | ä¹‹å‰å·²åˆ›å»º Accelerator | é‡å¯ Kernel |
| æ˜¾å­˜ä¸å‡åŒ€ | æŸäº›æ“ä½œåªåœ¨ä¸»è¿›ç¨‹ | ç¡®ä¿æ‰€æœ‰è¿›ç¨‹æ‰§è¡Œç›¸åŒä»£ç  |

---

# ğŸ“š æ·±å…¥ç†è§£ï¼šDataLoader åº•å±‚åŸç†

## DataLoader çš„æ ¸å¿ƒç»„ä»¶

```
DataLoader
    â”‚
    â”œâ”€â”€ Dataset         # æ•°æ®æºï¼Œå®ç° __getitem__ å’Œ __len__
    â”‚
    â”œâ”€â”€ Sampler         # å†³å®šå–æ•°æ®çš„é¡ºåº
    â”‚   â”œâ”€â”€ SequentialSampler     # é¡ºåºé‡‡æ · [0, 1, 2, 3, ...]
    â”‚   â”œâ”€â”€ RandomSampler         # éšæœºæ‰“ä¹±
    â”‚   â””â”€â”€ DistributedSampler    # ğŸ”¥ åˆ†å¸ƒå¼åˆ†ç‰‡é‡‡æ ·
    â”‚
    â”œâ”€â”€ BatchSampler    # å°†å¤šä¸ªç´¢å¼•ç»„æˆ batch
    â”‚
    â””â”€â”€ collate_fn      # å°†å¤šä¸ªæ ·æœ¬åˆå¹¶ä¸ºä¸€ä¸ª batch
```

## 1. Dataset

```python
class MyDataset(torch.utils.data.Dataset):
    def __init__(self, data):
        self.data = data
    
    def __len__(self):
        return len(self.data)  # æ•°æ®é›†å¤§å°
    
    def __getitem__(self, idx):
        # è¿”å›ç¬¬ idx ä¸ªæ ·æœ¬
        return {
            'input_ids': self.data[idx]['input_ids'],
            'labels': self.data[idx]['labels']
        }
```

## 2. Samplerï¼ˆé‡‡æ ·å™¨ï¼‰

### å•å¡é‡‡æ ·

```python
# shuffle=True æ—¶ä½¿ç”¨ RandomSampler
# å‡è®¾æ•°æ®é›†æœ‰ 10 ä¸ªæ ·æœ¬ [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
# RandomSampler ä¼šç”Ÿæˆéšæœºé¡ºåº: [7, 2, 9, 0, 5, 1, 8, 3, 6, 4]

loader = DataLoader(dataset, batch_size=3, shuffle=True)
# Batch 1: [7, 2, 9]
# Batch 2: [0, 5, 1]
# Batch 3: [8, 3, 6]
# Batch 4: [4]  (å‰©ä½™çš„)
```

### å¤šå¡åˆ†å¸ƒå¼é‡‡æ · (DistributedSampler)

```python
# å‡è®¾æ•°æ®é›†æœ‰ 12 ä¸ªæ ·æœ¬ï¼Œä½¿ç”¨ 4 å¼  GPU
# DistributedSampler ä¼šå°†æ•°æ®åˆ†æˆ 4 ä»½ï¼š

# GPU 0 (rank=0): [0, 4, 8]    # æ¯éš” 4 ä¸ªå–ä¸€ä¸ª
# GPU 1 (rank=1): [1, 5, 9]
# GPU 2 (rank=2): [2, 6, 10]
# GPU 3 (rank=3): [3, 7, 11]

# æ¯ä¸ª GPU åªçœ‹åˆ° 1/4 çš„æ•°æ®ï¼
```

### DistributedSampler æºç æ ¸å¿ƒé€»è¾‘

```python
class DistributedSampler:
    def __init__(self, dataset, num_replicas, rank):
        self.dataset = dataset
        self.num_replicas = num_replicas  # GPU æ•°é‡
        self.rank = rank                  # å½“å‰ GPU ç¼–å·
        
        # è®¡ç®—æ¯ä¸ª GPU å¤„ç†çš„æ ·æœ¬æ•°
        self.num_samples = len(dataset) // num_replicas
    
    def __iter__(self):
        indices = list(range(len(self.dataset)))
        
        # æ‰“ä¹±é¡ºåºï¼ˆæ‰€æœ‰ GPU ä½¿ç”¨ç›¸åŒçš„ç§å­ä¿è¯ä¸€è‡´ï¼‰
        random.seed(self.epoch)
        random.shuffle(indices)
        
        # ğŸ”¥ å…³é”®ï¼šæ¯ä¸ª GPU åªå–å±äºè‡ªå·±çš„é‚£éƒ¨åˆ†
        # rank=0 å– [0, 4, 8, ...]
        # rank=1 å– [1, 5, 9, ...]
        indices = indices[self.rank::self.num_replicas]
        
        return iter(indices)
```

## 3. collate_fnï¼ˆåˆå¹¶å‡½æ•°ï¼‰

```python
# é»˜è®¤çš„ collate_fn ä¼šå°†å¤šä¸ªæ ·æœ¬å †å æˆ batch
# è¾“å…¥: [{'x': tensor([1,2])}, {'x': tensor([3,4])}, {'x': tensor([5,6])}]
# è¾“å‡º: {'x': tensor([[1,2], [3,4], [5,6]])}  # shape: (3, 2)

# è‡ªå®šä¹‰ collate_fn ç¤ºä¾‹
def my_collate(batch):
    input_ids = torch.stack([item['input_ids'] for item in batch])
    labels = torch.stack([item['labels'] for item in batch])
    return {'input_ids': input_ids, 'labels': labels}

loader = DataLoader(dataset, batch_size=32, collate_fn=my_collate)
```

---

# ğŸ”§ æ·±å…¥ç†è§£ï¼šAccelerate åº•å±‚åŸç†

## Accelerator çš„æ ¸å¿ƒèŒè´£

```
Accelerator
    â”‚
    â”œâ”€â”€ æ£€æµ‹ç¯å¢ƒï¼ˆå•å¡/å¤šå¡/TPU/...ï¼‰
    â”‚
    â”œâ”€â”€ prepare() æ–¹æ³•
    â”‚   â”œâ”€â”€ åŒ…è£… Model â†’ DistributedDataParallel
    â”‚   â”œâ”€â”€ åŒ…è£… DataLoader â†’ æ·»åŠ  DistributedSampler
    â”‚   â””â”€â”€ åŒ…è£… Optimizer â†’ å¤„ç†æ¢¯åº¦ç´¯ç§¯
    â”‚
    â”œâ”€â”€ backward() æ–¹æ³•
    â”‚   â””â”€â”€ è‡ªåŠ¨æ¢¯åº¦åŒæ­¥
    â”‚
    â””â”€â”€ è¿›ç¨‹ç®¡ç†
        â”œâ”€â”€ is_main_process  # æ˜¯å¦æ˜¯ä¸»è¿›ç¨‹
        â”œâ”€â”€ process_index    # å½“å‰è¿›ç¨‹ç¼–å·
        â””â”€â”€ num_processes    # æ€»è¿›ç¨‹æ•°
```

## accelerator.prepare() å†…éƒ¨åšäº†ä»€ä¹ˆï¼Ÿ

### 1. åŒ…è£…æ¨¡å‹

```python
# prepare() å†…éƒ¨é€»è¾‘ï¼ˆç®€åŒ–ç‰ˆï¼‰
def prepare_model(model):
    # å°†æ¨¡å‹ç§»åˆ°å½“å‰ GPU
    model = model.to(accelerator.device)
    
    # ç”¨ DistributedDataParallel åŒ…è£…
    model = torch.nn.parallel.DistributedDataParallel(
        model,
        device_ids=[accelerator.local_process_index],
        output_device=accelerator.local_process_index
    )
    
    return model
```

### 2. åŒ…è£… DataLoader

```python
def prepare_dataloader(dataloader):
    # æ›¿æ¢é‡‡æ ·å™¨ä¸º DistributedSampler
    sampler = DistributedSampler(
        dataloader.dataset,
        num_replicas=accelerator.num_processes,  # GPU æ•°é‡
        rank=accelerator.process_index           # å½“å‰ GPU ç¼–å·
    )
    
    # åˆ›å»ºæ–°çš„ DataLoader
    new_dataloader = DataLoader(
        dataloader.dataset,
        batch_size=dataloader.batch_size,
        sampler=sampler,  # ğŸ”¥ å…³é”®ï¼šä½¿ç”¨åˆ†å¸ƒå¼é‡‡æ ·å™¨
        collate_fn=dataloader.collate_fn
    )
    
    return new_dataloader
```

### 3. è‡ªåŠ¨ç§»åŠ¨æ•°æ®åˆ° GPU

```python
# prepare() åçš„ DataLoader ä¼šè‡ªåŠ¨åŠ å…¥æ•°æ®ç§»åŠ¨é€»è¾‘
class AcceleratedDataLoader:
    def __iter__(self):
        for batch in self.original_dataloader:
            # ğŸ”¥ è‡ªåŠ¨å°†æ¯ä¸ª tensor ç§»åˆ°æ­£ç¡®çš„ GPU
            yield move_to_device(batch, accelerator.device)
```

## accelerator.backward() å†…éƒ¨åšäº†ä»€ä¹ˆï¼Ÿ

```python
def backward(self, loss):
    # 1. å¦‚æœä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼Œéœ€è¦ç¼©æ”¾ loss
    if self.gradient_accumulation_steps > 1:
        loss = loss / self.gradient_accumulation_steps
    
    # 2. è®¡ç®—æ¢¯åº¦
    loss.backward()
    
    # 3. ğŸ”¥ å¤šå¡æƒ…å†µä¸‹ï¼Œæ¢¯åº¦ä¼šè‡ªåŠ¨é€šè¿‡ DDP åŒæ­¥
    # DDP ä¼šåœ¨ backward æ—¶è‡ªåŠ¨è§¦å‘ all-reduce æ“ä½œ
    # å°†æ‰€æœ‰ GPU çš„æ¢¯åº¦æ±‚å¹³å‡
```

## æ¢¯åº¦åŒæ­¥åŸç†ï¼ˆAll-Reduceï¼‰

```
GPU 0: grad = [1.0, 2.0, 3.0]
GPU 1: grad = [2.0, 3.0, 4.0]
GPU 2: grad = [3.0, 4.0, 5.0]
GPU 3: grad = [4.0, 5.0, 6.0]

       â†“  All-Reduce (æ±‚å’Œ + å¹³å‡)

æ‰€æœ‰ GPU: grad = [2.5, 3.5, 4.5]  # (1+2+3+4)/4, (2+3+4+5)/4, (3+4+5+6)/4

# è¿™æ ·æ¯ä¸ª GPU ä¸Šçš„æ¨¡å‹å‚æ•°æ›´æ–°æ˜¯ä¸€è‡´çš„ï¼
```

---

## ğŸ“Š DataLoader å‚æ•°è¯¦è§£

```python
DataLoader(
    dataset,
    batch_size=32,          # æ¯ä¸ª batch çš„æ ·æœ¬æ•°
    shuffle=True,           # æ˜¯å¦æ‰“ä¹±ï¼ˆå•å¡ç”¨ï¼‰
    num_workers=4,          # æ•°æ®åŠ è½½çš„å¹¶è¡Œè¿›ç¨‹æ•°
    pin_memory=True,        # ğŸ”¥ åŠ é€Ÿ GPU æ•°æ®ä¼ è¾“
    drop_last=True,         # ä¸¢å¼ƒæœ€åä¸å®Œæ•´çš„ batch
    prefetch_factor=2,      # æ¯ä¸ª worker é¢„å–çš„ batch æ•°
    persistent_workers=True # ä¿æŒ worker è¿›ç¨‹å­˜æ´»
)
```

### å…³é”®å‚æ•°è§£é‡Š

| å‚æ•° | ä½œç”¨ | å»ºè®®å€¼ |
|------|------|--------|
| `num_workers` | CPU å¹¶è¡ŒåŠ è½½æ•°æ® | CPU æ ¸æ•° / GPU æ•° |
| `pin_memory` | æ•°æ®æ”¾å…¥é”é¡µå†…å­˜ï¼ŒåŠ é€Ÿ GPU ä¼ è¾“ | æ€»æ˜¯ `True` |
| `drop_last` | é¿å…æœ€å batch å¤§å°ä¸ä¸€è‡´ | è®­ç»ƒæ—¶ `True` |
| `prefetch_factor` | é¢„åŠ è½½å‡å°‘ GPU ç­‰å¾… | 2-4 |

---

## ğŸ§ª å®æˆ˜ç¤ºä¾‹ï¼šå®Œæ•´çš„å¤šå¡è®­ç»ƒä»£ç 

```python
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3"

import torch
from torch.utils.data import DataLoader, Dataset
from accelerate import Accelerator, notebook_launcher

class SimpleDataset(Dataset):
    def __init__(self, size=1000):
        self.data = torch.randn(size, 768)
        self.labels = torch.randint(0, 10, (size,))
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return {'x': self.data[idx], 'y': self.labels[idx]}

class SimpleModel(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.fc = torch.nn.Linear(768, 10)
    
    def forward(self, x):
        return self.fc(x)

def train():
    # 1. åˆå§‹åŒ– Accelerator
    accelerator = Accelerator()
    
    # 2. å‡†å¤‡æ•°æ®å’Œæ¨¡å‹
    dataset = SimpleDataset(10000)
    loader = DataLoader(dataset, batch_size=32)  # æ¯å¡ 32
    model = SimpleModel()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    criterion = torch.nn.CrossEntropyLoss()
    
    # 3. ğŸ”¥ Accelerate åŒ…è£…
    model, optimizer, loader = accelerator.prepare(model, optimizer, loader)
    
    # 4. è®­ç»ƒå¾ªç¯
    for epoch in range(3):
        total_loss = 0
        for batch in loader:
            outputs = model(batch['x'])
            loss = criterion(outputs, batch['y'])
            
            optimizer.zero_grad()
            accelerator.backward(loss)
            optimizer.step()
            
            total_loss += loss.item()
        
        if accelerator.is_main_process:
            print(f"Epoch {epoch}: Loss = {total_loss:.4f}")
    
    # 5. ä¿å­˜æ¨¡å‹
    if accelerator.is_main_process:
        torch.save(accelerator.unwrap_model(model).state_dict(), "model.pth")

# å¯åŠ¨
notebook_launcher(train, num_processes=4)
```

---

## ğŸ“– å‚è€ƒèµ„æ–™

- [PyTorch DataLoader å®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/stable/data.html)
- [HuggingFace Accelerate æ–‡æ¡£](https://huggingface.co/docs/accelerate)
- [PyTorch åˆ†å¸ƒå¼è®­ç»ƒæ•™ç¨‹](https://pytorch.org/tutorials/intermediate/ddp_tutorial.html)
